# SONY柏木さん
## 会社紹介
- 量よりも高付加価値を狙う会社戦略
- aiboにも認識や学習技術が使われている
- 高い技術を醸成する仕組み
- R&Dからも、商品サービス企画部に異動したりすることもできる
- 社内募集制度での異動
- クリエイティビティとテクノロジーで世界を感動で満たす

## Interspeech2019について
- 音声処理に関する学会
- 今年はオーストリア、４日間
- 採択率49%
- 9つものワークショップ
---
# The USTC System for BC2019
## 小谷さん（東大齋藤研究室D1）
- 声質変換
- TTSもしたい

## 論文概要
- 中国語TTSのタスクが一番良かったシステムを紹介

## Blizzard Challenge 2019
- ExpressiveなTTSを作れ！というタスク
- ブレスや抑揚の影響で変換前がそもそもExpressiveである

## FW
- BERTベースのフロントエンド

### 前処理
- 人手の処理のコスト
- どの語を強調するかも人手で設定
- Mel-cep, F0, V/UV
- HMM alignmentもした

## フロントエンド
- テキスト処理
  - アラビア数字など特殊な文字を変換
- 中国語のバウンダリー予測
- Focus wordsの予測も

### BERT
- 外部データとして小説とニュース記事
- BERTは100GBのデータを使っていた（補足）
- 出力が各識別タスクを解く。BERT本体のところはFIXなのかパラメタ更新しているのかどうか不明
- 計算資源はどうしている？（坂東さん）->企業と協力して資源を使わせてもらっているよう。潤沢。
- (坂東さん、質疑時の余談)NASなんかを産総研のABCI使って回している例はあったりするよう

## Duration Modeling
- 継続長をLogスケールで量子化してクロスエントロピーで学習
- Contextの入力：ピンインと四声
- Pre-trainedのマルチスピーカーモデルを1000時間以上使っていた

## Acoustic Modeling
- GANを使ってOversmoothingを回避している

## Vocoding
- 多人数話者でWavenet vocoder
- 16kHzと24kHzのWavenetをConcatした
- 位相はノイズで埋めてGriffin-Lim的なことをしているらしい

## まとめ
- BC2019
  - BERT-based
  - Autoregressive
  - GAN-based multi-task acoustic model
  - Wavenet-based neural vocoder
- まるで本人のような声が出ていて感動
---
# GMMNに基づく音声合成におけるグラム行列のスパース近似
## 須田さん 東大齋藤研究室D1
## SSW10について
- Neural voocoder / VC など
## 論文について
### 背景
- 一期一会音声合成
- 同じ発話にも揺らぎをもたせたい
- 1次から無限次元までのモーメントマッチングをする

### 提案法
- 平均だけ普通のNNで推定し、分散だけ上側のGMMNで学習する
- CMMDという学習基準をどう速く計算するかがポイント

### 生成的モーメントマッチングネットワーク
- 最大平均差異(MMD)を使う: 分布間距離
- 分布が同一ならMMDが0になる
- MMDの2乗を展開するとグラム行列が出てくる

### 条件付き生成的モーメントマッチングネットワーク
- 条件と観測のグラムベクトルが両方出てくる
- 観測と観測の類似度行列の逆を求めるのが遅い（毎エポック）ので、近似

### 近似式
- ミニバッチ単位で計算する：バッチ間での独立性を仮定して計算コストを下げる
- 乱択化フーリエ特徴（RFF）：縦長と横長の積に分解できる：IFFTは時間単位の期待値だと思う
- O(バッチサイズの３乗)　から O(N*バッチサイズの２乗)へ減らす

## 主観評価実験
- 自然性MOSで優れている
- 発話の違う感MOS：結局継続長だけ変えれば違う印象になる説があるらしい…

## まとめ
- RFFを使ってk-meansでミニバッチ分割して発話内変動のある音声合成ができた
- 聴覚的には継続長の影響が大きかった
- Future Work
  - VAE, GANとの比較
- 感想
  - モーメントマッチングネットワーク最高
  
## QA
- 自然音声での揺らぎは？
  - 継続長は自然音声でも結構ゆれている
  - 単純な２乗誤差だと自然音声の20%くらいしかゆれなかった
- バッチ分割のランダムさとクラスタリングしたものがあったが、このテクニックはオリジナルなのか？
  - k-meansでミニバッチに分割するものはすでにあったと思う
  - Gaussian ProcessのVCではよくやられているらしい
---
# Parrotron: End-to-end speech-to-speech Conversion Model and its applications to hearing-
## 橘さん(DeNA)
- 東芝R&Dで音声合成->NICT->DeNA

## 論文について
- 音声から音声へを波形直接変換
- Many-to-ne音声変換を高品質なレベルで実現
- 従来の音声変換以外にも他の用途に使える

## タスク
- Many-to-one音声変換
- 聴覚障碍者の音声変換
- ノイズ除去や音源分離

## 音声変換
- 包絡、F0, 非周期性指標を変換先の話者のパラメタにへんかnする
### 技術課題
- パラメタ変換が限定的：モデルを学習・変換する時に、
  - F0はオフセットやDynamic rangeを変えるだけだったりする 
  - 非周期性指標はそのままだったりする
- Alignment問題
  - 従来はDTWが直接品質に影響してしまう
- Many-to-one対応が高コスト
  - 多くの話者間のペアを学習しないといけない
  
### 提案法
#### WavenetをはじめとしてNeural Vocoderが登場
- Mel-specから直接波形生成することが可能になった
#### Seq2seqにより系列同士の学習が可能になった
- Attentionのやり方がAdditiveやSCENTなどがある
- ParrotronでもEncoderに対してASRのマルチタスク学習をさせている
#### 大規模書き起こし音声コーパスにTTS適用
- 変換先話者をParallel wavenetで生成
- 大規模音声コーパスが使える：ペアが求まる

### アルゴリズム
- メルスペクトログラムをWavenet vocoderに通す
- Conv2D -> LSTM4層
- DecoderはTacotron2のdecoderと同一構造
- ASR Decoder: Attention Layerの出力と１時刻前の音素予測結果を結合している->マルチタスクによりEncoderがPhonemeを保持する狙い

### 実験
- データセット
- 客観評価
  - ASRのWERで評価。7ポイントの性能改善。17.6%
  - Challengingな音声で評価してもMOSが4くらいになっている
- Many-to-one音声変換
  - 音声変換
  - 聴覚障碍者の15.4時間の音声で学習->変換することでクリアな音声に！
  - 背景ノイズの作成->音源分離タスクを解かせることで33.2->17.3%までWERが低減される
  
### まとめ
- End-to-and 音声変換ができた
- ASR Multitask 学習が有効
- 障碍者音声の明瞭化やノイズ除去という様々なタスクで有効性を確認
